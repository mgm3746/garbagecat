error.cms.concurrent.mode.failure=CMS concurrent mode failure. The concurrent collection of the old or perm/metaspace did not finish before the old or perm/metaspace became full. The JVM initiates a full GC using a slow (single threaded) serial collector in an attempt to free space. There is not enough space in the old generation to support the rate of promotion from the young generation or in the perm/metaspace to support the rate of perm/metaspace usage. The concurrent low pause collector measures the rate at which the the old generation is filling and the amount of time between collections and uses this historical data to calculate when to start the concurrent collection (plus adds some padding) so that it will finish just in time before the old generation becomes full. Possible causes: (1) The heap is too small. (2) There is a change in application behavior (e.g. a load increase) that causes the young promotion rate to exceed historical data. If this is the case, the concurrent mode failures will happen near the change in behavior, then after a few collections the CMS collector will adjust based on the new promotion rate. Performance will suffer for a short period until the CMS collector recalibrates. Use -XX:CMSInitiatingOccupancyFraction=N (default 92) to handle changes in application behavior (e.g. -XX:CMSInitiatingOccupancyFraction=85 -XX:+UseCMSInitiatingOccupancyOnly); however, the tradeoff is that there will be more collections. (3) The application has large variances in object allocation rates, causing large variances in young generation promotion rates, leading to the CMS collector not being able to accurately predict the time between collections. Use -XX:CMSIncrementalSafetyFactor=N (default 10) to start the concurrent collection NN% sooner than the calculated time. (4) There is premature promotion from the young to the old generation, causing the old generation to fill up with short-lived objects. The default value for -XX:MaxTenuringThreshold for the CMS collector is 0, meaning that objects surviving a young collection are immediately promoted to the old generation. Use -XX:MaxTenuringThreshold=32 to allow more time for objects to expire in the young generation. (5) If the old generation has available space, the cause is likely fragmentation. Fragmentation can be avoided by increasing the heap size, moving to the G1 collector which compacts the young and old generation during evacuation, or doing heap dump analysis to determine if there is any unintended object retention that can be addressed to decrease heap demands. (6) The perm/metaspace fills up during the CMS cycle. Increase the perm/metaspace size.
error.cms.concurrent.mode.interrupted=CMS concurrent collection of the old generation was interrupted by user requested GC (e.g. System.gc(), JVMTI ForceGarbageCollection) or serviceability requested GC (JVMTI ForceGarbageCollection, Heap Inspection, Heap Dump).
error.cms.par.new.gc.locker.failed=GCLocker initiated PAR_NEW collection failed due to there not being enough space in the old generation for the worst case scenario where all objects are promoted to the old generation (the young generation guarantee). Check if the old generation has available space, but it is not contiguous. When fragmentation is an issue, the concurrent low pause collector invokes a slow (single-threaded) serial collector to compact the heap. Tune to avoid fragmentation: (1) Increase the heap size. (2) Use -XX:CMSInitiatingOccupancyFraction=N (default 92) to run the CMS cycle more frequently to increase sweeping of dead objects in the old generation to free lists (e.g. -XX:CMSInitiatingOccupancyFraction=85 -XX:+UseCMSInitiatingOccupancyOnly). (3) Do heap dump analysis to determine if there is unintended object retention that can be addressed to decrease heap demands. Or move to a collector that handles fragmentation more efficiently: (1) G1 compacts the young and old generations during evacuation using a multi-threaded collector. (2) Shenandoah compacts concurrently. Temporarily add -XX:PrintFLSStatistics=1 and -XX:+PrintPromotionFailure to get additional insight into fragmentation.
error.cms.promotion.failed=CMS promotion failed. A young generation collection is not able to complete because there is not enough space in the old generation for promotion. The old generation has available space, but it is not contiguous. When fragmentation is an issue, the concurrent low pause collector invokes a slow (single-threaded) serial collector to compact the heap. Tune to avoid fragmentation: (1) Increase the heap size. (2) Use -XX:CMSInitiatingOccupancyFraction=N (default 92) to run the CMS cycle more frequently to increase sweeping of dead objects in the old generation to free lists (e.g. -XX:CMSInitiatingOccupancyFraction=85 -XX:+UseCMSInitiatingOccupancyOnly). (3) Do heap dump analysis to determine if there is unintended object retention that can be addressed to decrease heap demands. Or move to a collector that handles fragmentation more efficiently: (1) G1 compacts the young and old generations during evacuation using a multi-threaded collector. (2) Shenandoah compacts concurrently. Temporarily add -XX:PrintFLSStatistics=1 and -XX:+PrintPromotionFailure to get additional insight into fragmentation.
error.explicit.gc.serial.cms=Explicit garbage collection, i.e. calls to System.gc(), is causing the slow, single threaded serial old collector to be invoked. Either add -XX:+DisableExplicitGC to disable explicit garbage collection, or add -XX:+ExplicitGCInvokesConcurrent so explicit garbage collection is handled concurrently. Do not use -XX:+DisableExplicitGC if any of the following apply: (1) The application makes use of a direct buffer (e.g. java.nio.DirectByteBuffer) in combination with -XX:MaxDirectMemorySize=N[K|M|G], as the JVM uses explicit garbage collection to try to free space when MaxDirectMemorySize is reached. (2) The application makes remote method calls or exports remote objects like EJBs, as it can result in a memory leak due to the Distributed Garbage Collection (DGC) dependency on explicit garbage collection. To minimize DGC, test setting sun.rmi.dgc.client.gcInterval and sun.rmi.dgc.server.gcInterval to values longer than the default 1 second (JDK5 and earlier) or 1 hour (JDK6 on). For example, 4 hours (values in milliseconds): -Dsun.rmi.dgc.client.gcInterval=14400000 -Dsun.rmi.dgc.server.gcInterval=14400000. It is also possible the application depends on explicit garbage collection in some other way. For optimal performance, tune to avoid explicit garbage collection. Reference: https://access.redhat.com/solutions/21994
error.explicit.gc.serial.g1=Explicit garbage collection, i.e. calls to System.gc(), is causing the slow, single threaded G1_FULL_GC collector to be invoked. Either add -XX:+DisableExplicitGC to disable explicit garbage collection, or add -XX:+ExplicitGCInvokesConcurrent so explicit garbage collection is handled concurrently. Do not use -XX:+DisableExplicitGC if any of the following apply: (1) The application makes use of a direct buffer (e.g. java.nio.DirectByteBuffer) in combination with -XX:MaxDirectMemorySize=N[K|M|G], as the JVM uses explicit garbage collection to try to free space when MaxDirectMemorySize is reached. (2) The application makes remote method calls or exports remote objects like EJBs, as it can result in a memory leak due to the Distributed Garbage Collection (DGC) dependency on explicit garbage collection. To minimize DGC, test setting sun.rmi.dgc.client.gcInterval and sun.rmi.dgc.server.gcInterval to values longer than the default 1 second (JDK5 and earlier) or 1 hour (JDK6 on). For example, 4 hours (values in milliseconds): -Dsun.rmi.dgc.client.gcInterval=14400000 -Dsun.rmi.dgc.server.gcInterval=14400000. It is also possible the application depends on explicit garbage collection in some other way. For optimal performance, tune to avoid explicit garbage collection. Reference: https://access.redhat.com/solutions/21994
error.gc.time.limit.exceeded=The garbage collection overhead limit was reached. This happens when 98% of the total time is spent in garbage collection and less than 2% of the heap is recovered. This feature is a throttle to prevent applications from running for an extended period of time while making little or no progress because the heap is too small. If desired, this feature can be disabled with the -XX:-UseGCOverheadLimit option (e.g. to avoid "OutOfMemoryError: GC overhead limit exceeded", which does not initiate a heap dump when using -XX:+HeapDumpOnOutOfMemoryError, hoping to reach "OutOfMemoryError: Java heap space", which will trigger a heap dump with -XX:+HeapDumpOnOutOfMemoryError).
error.g1.evacuation.failure=A G1_YOUNG_PAUSE, G1_MIXED_PAUSE, and/or G1_YOUNG_INITIAL_MARK collection cannot happen due to "to-space exhausted" or "to-space overflow". There is not enough free space in the heap for survived and/or promoted objects, and the heap cannot be expanded. This is a very expensive operation. The Collection Set (CSet) and Remember Set (RSet) are fully re-scanned to understand the heap status, and the collector's ergonomics attempt to resolve the issue by dynamically re-sizing heap regions. If it cannot, it invokes a G1_FULL_GC in an attempt to reclaim enough space to continue. All of the following are possible resolutions: (1) Increase the heap size. (2) Increase -XX:G1ReservePercent (default 10%) and the heap size to increase the amount of to-space reserve memory. For, example, if you increase the reserve by 5% (to 15), you would also need to increase the heap size by 5%. (3) Reduce the -XX:InitiatingHeapOccupancyPercent (default 45) to start the marking cycle earlier. For example: -XX:InitiatingHeapOccupancyPercent=40. (4) Increase the number of parallel marking threads with -XX:ConcGCThreads. For example: -XX:ConcGCThreads=16. To determine which option is most appropriate, do analysis with ergonomic logging enabled with the -XX:+PrintAdaptiveSizePolicy option.
error.g1.humongous.jdk.old=Humongous objects are being allocated on an old version of the JDK that is not able to fully reclaim humongous objects during young collections. Upgrade to JDK8 update 60 or later.
error.metaspace.allocation.failure=Metaspace allocation failure. The Metaspace is not able to be resized, and the JVM is doing full, serial collections attempting to free Metaspace. The class metadata or compressed class pointers space is undersized, or there is a Metaspace leak. Increase the class metadata and compressed class pointers spaces to sufficiently large values to observe if there is a runaway leak or Metaspace usage levels off. For example, the following options will result in a 1536M Metaspace with a 512M space for class metadata and 1G space for compressed class pointers: -XX:MetaspaceSize=1536M -XX:MaxMetaspaceSize=1536M -XX:CompressedClassSpaceSize=1G.
error.gc.locker.retry=An object allocation failed as follows: (1) There was not a large enough free area in the heap. (2) GC was triggered. (3) The GC could not run because another thread owned the GCLocker running JNI code in a "critical region". (4) The JVM requested a "GCLocker Initiated GC" and waited. (5) The JNI code exited the "critical region" and released the GCLocker. (6) The JVM triggered a "GCLocker Initiated GC" minor collection and rescheduled the thread attempting the object allocation. (7) The object allocation failed again (either the GC did not free enough memory, or the freed memory was allocated by other threads). (8) If sequences #4-7 happen again, the GCLockerRetryAllocationCount limit (default 2) will be reached and "OutOfMemoryError: Java heap space" thrown. Possible solutions: (1) Increase the heap size to avoid the allocation failure. (2) Decrease the heap size to force more frequent collections to increase heap space free. (3) Move to the Shenandoah collector, which supports region pinning, so only the part of the heap containing the object passed into the JNI "critical region" is locked. (4) Increase the GCLockerRetryAllocationCount (e.g. -XX:+UnlockDiagnosticVMOptions -XX:GCLockerRetryAllocationCount=4).
error.oome.exit=The JVM exited due to OutOfMemoryError (e.g. -XX:+ExitOnOutOfMemoryError).
error.oome.metaspace=OutOfMemoryError: Metaspace. Check the end of the gc log for details.
error.physical.memory=The memory reserved for the heap and perm/metaspace is greater than the physical memory. This can lead to swapping (very bad for Java performance) or the process being terminated (oom killer). Either increase physical memory or decrease heap and/or perm/metaspace size to avoid swapping. The memory required by the JVM process is the sum of the following: (1) Heap. (2) Perm/Metaspace. (3) Thread Stack (thread stack size X number of threads). (4) JVM native memory. (5) A safety factor.
error.serial.gc.cms=The CMS_SERIAL_OLD collector is being invoked for one of the following reasons: (1) Fragmentation. The concurrent low pause collector does not compact. When fragmentation becomes an issue a serial collection compacts the heap. If the old generation has available space, the cause is likely fragmentation. Fragmentation can be avoided by increasing the heap size. (2) Metaspace class metadata or compressed class pointers allocation failure. The GC attempts to free/resize metaspace. (3) Resizing perm gen. If perm gen occupancy is near perm gen allocation, the cause is likely perm gen. Perm gen resizing can be avoided by setting the minimum perm gen size equal to the the maximum perm gen size. For example: -XX:PermSize=256M -XX:MaxPermSize=256M. (4) Undetermined reasons. Possibly the JVM requires a certain amount of heap or combination of resources that is not being met, and consequently the concurrent low pause collector is not used despite being specified with the -XX:+UseConcMarkSweepGC option. The CMS_SERIAL_OLD collector is a serial (single-threaded) collector, which means it can take a very long time to collect a large heap. For optimal performance, tune to avoid serial collections.
error.serial.gc.g1=The G1_FULL_GC_SERIAL collector is being invoked due to the old or perm gen/metaspace filling up. Old space causes: (1) It is filled with humongous objects. Humongous objects can only be collected by the G1_FULL_GC_SERIAL collector prior to JDK8u40. (2) The heap is swamped before the marking cycle is able to complete and a mixed collection reclaim space. Reduce the -XX:InitiatingHeapOccupancyPercent (default 45) to start the marking cycle earlier. For example: -XX:InitiatingHeapOccupancyPercent=40. (3) The heap is simply too small, (4) Bugs in JDK7 that cause G1 Full GC collections. For example: http://bugs.java.com/bugdatabase/view_bug.do?bug_id=8030849. The G1_FULL_GC_SERIAL collector is a single-threaded collector, which means it can take a very long time to collect a large heap. For optimal performance, tune to avoid serial collections.
error.serial.gc.parallel=The PARALLEL_SERIAL_OLD (single-threaded) collector is being invoked. Add -XX:+UseParallelOldGC or replace -XX:-UseParallelOldGC with -XX:+UseParallelOldGC to use the more efficient PARALLEL_COMPACTING_OLD (multi-threaded) collector added in JDK 6.
error.shared.memory.12=Failed to reserve shared memory. (error = 12). Check if large pages are not set up correctly, or there are not enough pages. Reference: https://access.redhat.com/solutions/22924.
error.shenandoah.full.gc=The SHENANDOAH_FULL_GC collector is being invoked as a last ditch effort to avoid OutOfMemoryError. It is an indication of significant allocation pressure.
error.unidentified.log.lines.preparse=Unidentified log line(s). Try running with the -p (preparsing) option.   
info.first.timestamp.threshold.exceeded=First timestamp is greater than threshold. Partial log file or unrecognized logging format.
info.g1.humongous.allocation=G1 Humongous allocations. Frequent humongous allocations can cause the heap to become fragmented and have excessive unused space (the space between the humongous object and the end of the region is unused).
info.jdk.ancient=The JDK is very old (>1 yr).
info.new.ratio.inverted=Young space >= old space.
info.perm.gen=A very old JDK with a permanent generation is being used. The decommissioning of the perm gen space began in JDK7 when interned strings and class static variables were moved to the Java heap, and symbols were moved to the native heap. In JDK8 the perm gen space was fully replaced by the metaspace, a native space holding only class metadata.
info.shenandoah.uncommit.disabled=Min heap equal to max heap, disabling ShenandoahUncommit.
info.swap.disabled=Swap has been disabled. This can be an indication the JVM is running in a container environment. Reference: https://access.redhat.com/solutions/3242331
info.swapping=Some swap space was being used when the GC log file was created (at JVM startup or file rotation). This is not necessarily bad, as it is only a snapshot in time, and it doesn't necessarily mean the Java process is swapping. Swapping is very bad for Java performance. Verify the Java process is not swapping.
info.thread.dump=Logging includes one or more thread dumps.
info.unaccounted.options.disabled=Unaccounted disabled JVM options: 
info.unidentified.log.line.last=Last log line(s) not identified. This is typically caused by the GC log being copied while the JVM is in the middle of logging an event, resulting in truncated logging. If it is not due to truncated logging, report the unidentified logging line: https://github.com/mgm3746/garbagecat/issues.
info.z.statistics.interval=Diagnostic ZGC statistics are being output every ZStatisticsInterval interval (default 10 seconds). This is very verbose logging generally enabled for short periods of time to address specific tuning issues, not recommended/supported for general production use. Remove -XX:+UnlockDiagnosticVMOptions and any explicit -XX:ZStatisticsInterval setting when relevant troubleshooting is completed.
warn.application.logging=Garbage collection logging mixed with application logging. Garbage collection logging should be logged to a dedicated file using the -Xloggc option. For example: -Xloggc:gc.log.`date +%Y%m%d%H%M%S`.
warn.application.stopped.time.missing=Application stopped time missing. Enable with -XX:+PrintGCApplicationStoppedTime (<= JDK8) or with safepoint logging at info level (e.g. -Xlog:gc*,safepoint=info:file=gc.log:uptime:filecount=4,filesize=50M). Required to determine overall throughput and identify throughput and pause issues not related to garbage collection, as many JVM operations besides garbage collection require all threads to reach a safepoint to execute. Reference: https://access.redhat.com/solutions/18656
warn.class.histogram=Class histogram output due to one of the following options: -XX:+PrintClassHistogram, -XX:+PrintClassHistogramBeforeFullGC, -XX:+PrintClassHistogramAfterFullGC. These are heavyweight options that can output tens of thousands of logging lines and have limited use cases for troubleshooting memory leaks. Generally memory leaks are investigated by getting a heap dump. If there is not a good use case for this output, do not enable it.
warn.cms.class.unloading.not.enabled=The CMS collector does not always collect perm/metaspace by default (e.g. prior to JDK 1.8). Add -XX:+CMSClassUnloadingEnabled to collect perm/metaspace in the CMS concurrent cycle and avoid perm/metaspace collections being done by a slow (single threaded) serial collector.
warn.cms.initial.mark.low.parallelism=CMS initial mark low parallelism: (1) If using JDK6 or earlier, initial mark is single-threaded. Consider upgrading to JDK7 or later for multi-threaded initial mark. (2) If using JDK7, add -XX:+CMSParallelInitialMarkEnabled, as initial mark is single-threaded by default in JDK7. (3) Check if multi-threaded remark is disabled with -XX:-CMSParallelInitialMarkEnabled, and replace with -XX:+CMSParallelInitialMarkEnabled. (3) Check for swapping and if the number of GC threads (-XX:ParallelGCThreads=<n>) is appropriate for the number of cpu/cores and any processes sharing cpu.
warn.cms.remark.low.parallelism=CMS remark low parallelism: (1) If using JDK7 or earlier, add -XX:+CMSParallelRemarkEnabled, as remark is single-threaded by default in JDK7 and earlier. (2) Check if multi-threaded remark is disabled with -XX:-CMSParallelRemarkEnabled, and replace with -XX:+CMSParallelRemarkEnabled. (4) Add -XX:+ParallelRefProcEnabled to enable multi-threaded reference processing if the "weak refs processing" time is a significant amount of the total CMS remark time. (5) Check for swapping and if the number of GC threads (-XX:ParallelGCThreads=<n>) is appropriate for the number of cpu/cores and any processes sharing cpu.
warn.datestamp.approximate=The datestamps reported are approximate based on the gc file creation date.
warn.explicit.gc.diagnostic=Garbage collection is being explicitly invoked (e.g. jcmd <pid> GC.run).
warn.explicit.gc.g1.young.initial.mark=Explicit garbage collection, i.e. calls to System.gc(), is causing the G1_YOUNG_INITIAL_MARK collector to be invoked. Add -XX:+DisableExplicitGC to disable explicit garbage collection if the application does not depend on explicit garbage collection. Do not use -XX:+DisableExplicitGC if any of the following apply: (1) The application makes use of a direct buffer (e.g. java.nio.DirectByteBuffer) in combination with -XX:MaxDirectMemorySize=N[K|M|G], as the JVM uses explicit garbage collection to try to free space when MaxDirectMemorySize is reached. (2) The application makes remote method calls or exports remote objects like EJBs, as it can result in a memory leak due to the Distributed Garbage Collection (DGC) dependency on explicit garbage collection. To minimize DGC, test setting sun.rmi.dgc.client.gcInterval and sun.rmi.dgc.server.gcInterval to values longer than the default 1 second (JDK5 and earlier) or 1 hour (JDK6 on). For example, 4 hours (values in milliseconds): -Dsun.rmi.dgc.client.gcInterval=14400000 -Dsun.rmi.dgc.server.gcInterval=14400000. It is also possible the application depends on explicit garbage collection in some other way. For optimal performance, tune to avoid explicit garbage collection. Reference: https://access.redhat.com/solutions/21994
warn.explicit.gc.jvmti=The JVM Tools Interface (TI) API is being called (e.g. by some tool) to explicitly invoke garbage collection.
warn.explicit.gc.parallel=Explicit garbage collection, i.e. calls to System.gc(), is causing the PARALLEL_COMPACTING_OLD collector to be invoked. Add -XX:+DisableExplicitGC to disable explicit garbage collection if the application does not depend on explicit garbage collection. Do not use -XX:+DisableExplicitGC if any of the following apply: (1) The application makes use of a direct buffer (e.g. java.nio.DirectByteBuffer) in combination with -XX:MaxDirectMemorySize=N[K|M|G], as the JVM uses explicit garbage collection to try to free space when MaxDirectMemorySize is reached. (2) The application makes remote method calls or exports remote objects like EJBs, as it can result in a memory leak due to the Distributed Garbage Collection (DGC) dependency on explicit garbage collection. To minimize DGC, test setting sun.rmi.dgc.client.gcInterval and sun.rmi.dgc.server.gcInterval to values longer than the default 1 second (JDK5 and earlier) or 1 hour (JDK6 on). For example, 4 hours (values in milliseconds): -Dsun.rmi.dgc.client.gcInterval=14400000 -Dsun.rmi.dgc.server.gcInterval=14400000. It is also possible the application depends on explicit garbage collection in some other way. For optimal performance, tune to avoid explicit garbage collection. Reference: https://access.redhat.com/solutions/21994
warn.explicit.gc.serial=Explicit garbage collection, i.e. calls to System.gc(), is causing the slow, single threaded SERIAL_OLD collector to be invoked. Add -XX:+DisableExplicitGC to disable explicit garbage collection if the application does not depend on explicit garbage collection. Do not use -XX:+DisableExplicitGC if any of the following apply: (1) The application makes use of a direct buffer (e.g. java.nio.DirectByteBuffer) in combination with -XX:MaxDirectMemorySize=N[K|M|G], as the JVM uses explicit garbage collection to try to free space when MaxDirectMemorySize is reached. (2) The application makes remote method calls or exports remote objects like EJBs, as it can result in a memory leak due to the Distributed Garbage Collection (DGC) dependency on explicit garbage collection. To minimize DGC, test setting sun.rmi.dgc.client.gcInterval and sun.rmi.dgc.server.gcInterval to values longer than the default 1 second (JDK5 and earlier) or 1 hour (JDK6 on). For example, 4 hours (values in milliseconds): -Dsun.rmi.dgc.client.gcInterval=14400000 -Dsun.rmi.dgc.server.gcInterval=14400000. It is also possible the application depends on explicit garbage collection in some other way. For optimal performance, tune to avoid explicit garbage collection. Reference: https://access.redhat.com/solutions/21994
warn.explicit.gc.serial.parallel=Explicit garbage collection, i.e. calls to System.gc(), is causing the slow, single threaded PARALLEL_SERIAL_OLD collector to be invoked. Add -XX:+DisableExplicitGC to disable explicit garbage collection if the application does not depend on explicit garbage collection. Do not use -XX:+DisableExplicitGC if any of the following apply: (1) The application makes use of a direct buffer (e.g. java.nio.DirectByteBuffer) in combination with -XX:MaxDirectMemorySize=N[K|M|G], as the JVM uses explicit garbage collection to try to free space when MaxDirectMemorySize is reached. (2) The application makes remote method calls or exports remote objects like EJBs, as it can result in a memory leak due to the Distributed Garbage Collection (DGC) dependency on explicit garbage collection. To minimize DGC, test setting sun.rmi.dgc.client.gcInterval and sun.rmi.dgc.server.gcInterval to values longer than the default 1 second (JDK5 and earlier) or 1 hour (JDK6 on). For example, 4 hours (values in milliseconds): -Dsun.rmi.dgc.client.gcInterval=14400000 -Dsun.rmi.dgc.server.gcInterval=14400000. It is also possible the application depends on explicit garbage collection in some other way. For optimal performance, tune to avoid explicit garbage collection. Reference: https://access.redhat.com/solutions/21994
warn.explicit.gc.unknown=Explicit garbage collection, i.e. calls to System.gc(), is causing a full GC. Add -XX:+DisableExplicitGC to disable explicit garbage collection if the application does not depend on explicit garbage collection. Do not use -XX:+DisableExplicitGC if any of the following apply: (1) The application makes use of a direct buffer (e.g. java.nio.DirectByteBuffer) in combination with -XX:MaxDirectMemorySize=N[K|M|G], as the JVM uses explicit garbage collection to try to free space when MaxDirectMemorySize is reached. (2) The application makes remote method calls or exports remote objects like EJBs, as it can result in a memory leak due to the Distributed Garbage Collection (DGC) dependency on explicit garbage collection. To minimize DGC, test setting sun.rmi.dgc.client.gcInterval and sun.rmi.dgc.server.gcInterval to values longer than the default 1 second (JDK5 and earlier) or 1 hour (JDK6 on). For example, 4 hours (values in milliseconds): -Dsun.rmi.dgc.client.gcInterval=14400000 -Dsun.rmi.dgc.server.gcInterval=14400000. It is also possible the application depends on explicit garbage collection in some other way. For optimal performance, tune to avoid explicit garbage collection. Reference: https://access.redhat.com/solutions/21994
warn.gc.locker=GCLocker GC due to the following sequence of events: (1) An object allocation failed due to not a large enough free area in the heap. (2) GC was triggered. (3) The GC could not run because another thread owned the GCLocker running JNI code in a "critical region". (4) The JVM requested a "GCLocker Initiated GC" and waited. (5) The JNI code exited the "critical region" and released the GCLocker. (6) The JVM triggered a "GCLocker Initiated GC" minor collection and rescheduled the thread attempting the object allocation. Possible next steps: (1) Increase the heap size to avoid the allocation failure. (2) Decrease the heap size to force more frequent collections to increase heap space free. (3) Move to the Shenandoah collector, which supports region pinning, so only the part of the heap containing the object passed into the JNI "critical region" is locked. (4) Migrate JNI criticals to safe alternatives (e.g. GetArrayElements, GetArrayRegion) or rewrite in Java. Reference: https://bugs.openjdk.org/browse/JDK-8199919.
warn.gc.safepoint.ratio=Safepoint time >20% more than GC time. Possible reasons: (1) Time getting to GC safepoint is not included in GC time (e.g. suspending concurrent threads). (2) I/O issues writing to a gc.log blocking the entire JVM (n/a JDK17+ which uses async logging). (3) Other JVM operations that require a safepoint: Deoptimization, PrintThreads, ThreadDump, etc. Reference: https://access.redhat.com/solutions/3973431.
warn.gc.safepoint.ratio.jdk17=Safepoint time >20% more than GC time. Possible reasons: (1) Time getting to GC safepoint is not included in GC time (e.g. suspending concurrent threads). (2) Other JVM operations that require a safepoint: Deoptimization, PrintThreads, ThreadDump, etc. Reference: https://access.redhat.com/solutions/3973431.
warn.gc.stopped.ratio=Stopped time >20% more than GC time. Possible reasons: (1) Time getting to GC safepoint is not included in GC time (e.g. suspending concurrent threads). (2) I/O issues writing to a gc.log blocking the entire JVM (n/a JDK17+ which uses async logging). (3) Other JVM operations that require a safepoint: Deoptimization, PrintThreads, ThreadDump, etc. Reference: https://access.redhat.com/solutions/3973431.
warn.gc.stopped.ratio.jdk17=Stopped time >20% more than GC time. Possible reasons: (1) Time getting to GC safepoint is not included in GC time (e.g. suspending concurrent threads). (2) Other JVM operations that require a safepoint: Deoptimization, PrintThreads, ThreadDump, etc. Reference: https://access.redhat.com/solutions/3973431.
warn.heap.dump.initiated.gc=A garbage collection was initiated by a heap dump specifying that only live objects be included (e.g. jmap -J-d64 -dump:live,format=b,file=heap.hprof <JAVA_PID>). A heap dump significantly impacts JVM performance as it requires the JVM to be at a safepoint (all threads stopped) and should be limited to troubleshooting issues that require this heavyweight data. If a heapdump is required, consider including both live and dead objects (e.g. jmap -J-d64 -dump:format=b,file=heap.hprof <JAVA_PID>) to avoid extra, unnecessary garbage collections.
warn.heap.inspection.initiated.gc=A tool such as jmap (e.g. jmap -histo:live <JAVA_PID>) or Flight Recorder is initiating full garbage collections in order to monitor heap usage. If monitoring is excessive, it can significantly impact JVM performance (throughput).
warn.heap.min.not.equal.max=For production environments, it is recommended to set the minimum heap size (-Xms, -XX:InitialHeapSize) and the maximum heap size (-Xmx, -XX:MaxHeapSize) to equal values for the following reasons: (1) It avoids the major (full) garbage collection the JVM has to do to resize the heap space. (2) If using large pages, memory is reserved for the JVM based on the maximum heap size, and there is no expectation that the memory will be used by any other process. (3) If using large pages, it avoids the case when other processes using large pages exhaust the large page memory and the OS reverts to using regular pages when the JVM asks to allocate more memory. For example: -Xms4096M -Xmx4096M.
warn.jvm.options.override=The JVM options passed in the command line are overriding ones found in gc logging. 
warn.parallelism.inverted=Inverted parallelism. With parallel (multi-threaded) collector events, the "user" + "sys" time should be approximately equal to the "real" (wall) time multiplied by the # of GC threads. For example, if there are 3 GC threads we would expect a parallel collection that takes 1 second of "real" time to take approximately 3 seconds of "user" + "sys" time. The parallelism is 3x. If the parallelism is 1x ("user" + "sys" = "real"), the parallel collection is not offering any efficiency over a serial (single-threaded) collection. When "user" + "sys" < "real", the parallelism is inverted. Inverted parallelism can be a sign of high i/o (e.g. disk or network access) or not enough CPU (e.g. GC threads competing with each other or other processes). Check for swapping and if the number of GC threads (-XX:ParallelGCThreads=<n>) is appropriate for the number of cpu/cores and any processes sharing cpu. Reference: https://access.redhat.com/solutions/159283.
warn.perm.min.not.equal.max=For production environments, it is recommended to set the minimum permanent generation size (-XX:PermSize) and maximum permanent generation size (-XX:MaxPermSize) to equal values for the following reasons: (1) It avoids the major (full) garbage collection the JVM has to do to resize the permanent generation space. (2) If using large pages, memory is reserved for the JVM based on the maximum permanent generation size, and there is no expectation that the memory will be used by any other process. (3) If using large pages, it avoids the case when other processes using large pages exhaust the large page memory and the OS reverts to using regular pages when the JVM asks to allocate more memory. For example: -XX:PermSize=256M -XX:MaxPermSize=256M.
warn.perm.size.not.set=The permanent generation size should be explicitly set. The default permanent generation size is very small (e.g. 64MB in server mode), so not setting it can lead to OutOfMemoryError. Explicitly set the permanent generation size. For example: -XX:PermSize=128M -XX:MaxPermSize=128M.
warn.print.commandline.flags=Add -XX:+PrintCommandLineFlags to output the JVM command line options at the beginning of the GC log. This is critical information for GC analysis.
warn.print.commandline.flags.disabled=Replace -XX:-PrintCommandLineFlags with -XX:+PrintCommandLineFlags (note "+" vs "-") to output the JVM command line options at the beginning of the GC log. This is critical information for GC analysis.
warn.print.gc.cause.disabled=Printing trigger information is disabled with -XX:-PrintGCCause. Typically you want to enable it: -XX:+PrintGCCause. Or remove the option if using JDK8, where it is enabled by default.
warn.print.gc.cause.missing=Add -XX:+PrintGCCause to print trigger information with JDK7. For example: "GC pause (G1 Evacuation Pause) (young)" vs. "GC pause (young)". Enabled by default in JDK8.
warn.print.gc.cause.not.enabled=Printing trigger information is not enabled. This is critical information for troubleshooting serial collections. Enabled by default in JDK8+. Add -XX:+PrintGCCause to print trigger information with JDK7. Do not disable it (remove -XX:-PrintGCCause) with JDK8+.
warn.safepoint.stats=Safepoint statistics will be missing some time if running JDK17 prior to update 8. It was not possible to identify the JDK version to determine parsing. Reference: https://bugs.openjdk.org/browse/JDK-8297154.
warn.serial.gc=A SERIAL collector is being invoked. SERIAL collectors are single-threaded, which means they can take a long time to collect a large heap. For optimal performance on multi cpu/core systems, tune to avoid serial collections.
warn.serialism.inverted=Inverted serialism. With serial collector events, the "user" + "sys" time should be approximately equal to the "real" (wall) time. For example, we would expect a serial collection that takes 3 seconds of "real" time to take approximately 3 seconds of "user" + "sys" time. When "user" + "sys" < "real", the serialism is inverted. Inverted serialism can be a sign of high i/o (e.g. disk or network access) or not enough CPU (e.g. threads competing with other processes). Check for swapping and if the number of cpu/cores is appropriate for the processes sharing cpu. Reference: https://access.redhat.com/solutions/159283.
warn.sys.gt.user=sys (kernel space) greater than user time. GC code runs in user space, so this can be an indication of an unhealthy environment (e.g. heavy disk i/o, swapping, high cpu, overloaded VM). Reference: https://access.redhat.com/solutions/6968664.
warn.unidentified.log.line.report=Unidentified log line(s). Please submit an issue so we can investigate: https://github.com/mgm3746/garbagecat/issues. 